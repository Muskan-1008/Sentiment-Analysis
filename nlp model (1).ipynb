{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379a44da",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4523dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import xgboost\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, make_scorer,accuracy_score ,classification_report, confusion_matrix\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc79c88",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9117cb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\91741\\\\Downloads\\\\Restaurant_Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9e96a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "885f311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Review            1000 non-null   object\n",
      " 1   Liked             1000 non-null   int64 \n",
      " 2   tokenized_review  1000 non-null   object\n",
      " 3   vector_rep        1000 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5467cb98",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9671519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Liked', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef8b37",
   "metadata": {},
   "source": [
    "**This shows that dataset is balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4576fce",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a61d5",
   "metadata": {},
   "source": [
    "### Lowering of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6aee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b2483",
   "metadata": {},
   "source": [
    "### Removing things other than Alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d2dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].replace('[^a-zA-Z]',' ',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace8263",
   "metadata": {},
   "source": [
    "### Double Spaces substituted with Single Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497945fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].replace(r' +', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f47919",
   "metadata": {},
   "source": [
    "### Removing Html Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973749af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<*.?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d94246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fa654",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fdb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "remove=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81db7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in remove:\n",
    "        text=text.replace(char,'')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8165161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57918f",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ec8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Join tokens back into a preprocessed text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7360bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        wow loved place\n",
       "1                                             crust good\n",
       "2                                    tasty texture nasty\n",
       "3      stopped late may bank holiday rick steve recom...\n",
       "4                            selection menu great prices\n",
       "                             ...                        \n",
       "995                    think food flavor texture lacking\n",
       "996                              appetite instantly gone\n",
       "997                      overall impressed would go back\n",
       "998    whole experience underwhelming think go ninja ...\n",
       "999    wasted enough life poured salt wound drawing t...\n",
       "Name: Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848dcd1",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7771fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14703b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0c5378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "206c60d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow loved this place'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6707ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture wa just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu wa great and so were...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                               wow loved this place      1\n",
       "1                                  crust is not good      0\n",
       "2            not tasty and the texture wa just nasty      0\n",
       "3  stopped by during the late may bank holiday of...      1\n",
       "4  the selection on the menu wa great and so were...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058d0cd",
   "metadata": {},
   "source": [
    "# Splitting of data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41edfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['Review']\n",
    "y=df['Liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb068a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   wow loved this place\n",
       "1                                      crust is not good\n",
       "2                not tasty and the texture wa just nasty\n",
       "3      stopped by during the late may bank holiday of...\n",
       "4      the selection on the menu wa great and so were...\n",
       "                             ...                        \n",
       "995    i think food should have flavor and texture an...\n",
       "996                              appetite instantly gone\n",
       "997     overall i wa not impressed and would not go back\n",
       "998    the whole experience wa underwhelming and i th...\n",
       "999    then a if i hadn t wasted enough of my life th...\n",
       "Name: Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "247a51a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: Liked, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9531f3",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e5d3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c2f0d",
   "metadata": {},
   "source": [
    "# Text to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e4f6c",
   "metadata": {},
   "source": [
    "### 1) Bag of Words=A bag of words is a representation of text that describes the occurrence of words within a document.\n",
    "### 2) Tfidf Vectorizer(Term Frequency-Inverse Document Frequency) is a commonly used technique in NLP to determine the significance of words in a document .\n",
    "### 3) Word2Vec= It is a numeric vector input that represents a word in a lower-dimensional space. It allows words with similar meaning to have a similar representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c55f9",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b4c14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "CV=CountVectorizer()\n",
    "count_train=CV.fit_transform(X_train)\n",
    "count_test=CV.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0a499",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0897202",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9a0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        97\n",
      "           1       0.84      0.80      0.82       103\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.82      0.81       200\n",
      "weighted avg       0.82      0.81      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [21 82]]\n",
      "=======================================================\n",
      "accuracy score 0.815\n"
     ]
    }
   ],
   "source": [
    "lgc = LogisticRegression()\n",
    "lgc.fit(count_train, y_train)\n",
    "# make predictions on the test data\n",
    "y_pred = lgc.predict(count_test)\n",
    "# calculate metric evaluation and confusion matrix\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038ae34",
   "metadata": {},
   "source": [
    "## Cross Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827cac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.775 0.75  0.775 0.8   0.85 ]\n",
      "Mean Accuracy: 0.7899999999999999\n",
      "Best Parameters: {'C': 1.0, 'max_iter': 50}\n",
      "Best Accuracy Score: 0.7899999999999999\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        97\n",
      "           1       0.84      0.80      0.82       103\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.82      0.81       200\n",
      "weighted avg       0.82      0.81      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [21 82]]\n",
      "=======================================================\n",
      "accuracy score 0.815\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(lgc, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0], \n",
    "    'max_iter': [50, 100, 200]   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lgc, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb3408",
   "metadata": {},
   "source": [
    "## Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2be13bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        97\n",
      "           1       0.81      0.77      0.79       103\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[79 18]\n",
      " [24 79]]\n",
      "=======================================================\n",
      "accuracy score 0.79\n"
     ]
    }
   ],
   "source": [
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(count_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(count_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e97ae",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "397c1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.775   0.76875 0.79375 0.75    0.825  ]\n",
      "Mean Accuracy: 0.7825000000000001\n",
      "Best Parameters: {'C': 1.0, 'max_iter': 50}\n",
      "Best Accuracy Score: 0.78875\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80        97\n",
      "           1       0.82      0.79      0.80       103\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.80       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[79 18]\n",
      " [22 81]]\n",
      "=======================================================\n",
      "accuracy score 0.8\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0],  \n",
    "    'max_iter': [50, 100, 200] }  \n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52a0d3",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03fde7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        97\n",
      "           1       0.81      0.76      0.78       103\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.78       200\n",
      "weighted avg       0.79      0.79      0.78       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[79 18]\n",
      " [25 78]]\n",
      "=======================================================\n",
      "accuracy score 0.785\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(count_train, y_train)\n",
    "# make predictions on the test data\n",
    "y_pred = RFC.predict(count_test)\n",
    "# calculate metric evaluation and confusion matrix\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819e0e5",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47f39edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.7875  0.70625 0.75625 0.79375 0.83125]\n",
      "Mean Accuracy: 0.775\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "Best Accuracy Score: 0.7899999999999999\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        97\n",
      "           1       0.86      0.79      0.82       103\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.83      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[84 13]\n",
      " [22 81]]\n",
      "=======================================================\n",
      "accuracy score 0.825\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(RFC, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],     # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]        # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RFC, param_grid, cv=5, scoring='accuracy')\n",
    "random_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_RFC = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "predictions= best_RFC.predict(count_test)\n",
    "\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, predictions))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524c39c",
   "metadata": {},
   "source": [
    "## Xgboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8ce7836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78        97\n",
      "           1       0.82      0.70      0.75       103\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.76       200\n",
      "weighted avg       0.77      0.77      0.76       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [31 72]]\n",
      "=======================================================\n",
      "accuracy score 0.765\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(count_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb.predict(count_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef433c4",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f86b1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.75625 0.70625 0.73125 0.76875 0.7625 ]\n",
      "Mean Accuracy: 0.7449999999999999\n",
      "Best Parameters: {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 5, 'eta': 0.09}\n",
      "Best Accuracy Score: 0.6625\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73        97\n",
      "           1       0.79      0.55      0.65       103\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.72      0.70      0.69       200\n",
      "weighted avg       0.72      0.69      0.69       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[82 15]\n",
      " [46 57]]\n",
      "=======================================================\n",
      "accuracy score 0.695\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb,count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "params={'eta':[0.004,0.006,0.009,0.01,0.03,0.05,0.07,0.09,0.1,0.3],\n",
    " 'gamma':[5,10,15,20,25,30,40,50,60,70,80,90,100],\n",
    " 'max_depth':[int(x) for x in np.linspace(5,30,num=6)],\n",
    " 'min_child_weight':[3,4,5,6,7],\n",
    " 'subsample':[0.6,0.7,0.8]}\n",
    "\n",
    "    \n",
    "random_search = RandomizedSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
    "random_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "y_pred_tuned = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108dcd52",
   "metadata": {},
   "source": [
    "# Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f787458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "count_train=tfidf.fit_transform(X_train)\n",
    "count_test=tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffac2a",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e1f7c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "debe3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83        97\n",
      "           1       0.85      0.80      0.82       103\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.83      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[83 14]\n",
      " [21 82]]\n",
      "=======================================================\n",
      "accuracy score 0.825\n"
     ]
    }
   ],
   "source": [
    "lgc = LogisticRegression()\n",
    "lgc.fit(count_train, y_train)\n",
    "# make predictions on the test data\n",
    "y_pred = lgc.predict(count_test)\n",
    "# calculate metric evaluation and confusion matrix\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf56022",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8218492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.80625 0.75625 0.75625 0.80625 0.83125]\n",
      "Mean Accuracy: 0.79125\n",
      "Best Parameters: {'C': 2.0, 'max_iter': 50}\n",
      "Best Accuracy Score: 0.8012499999999999\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        97\n",
      "           1       0.86      0.81      0.83       103\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.84      0.84      0.83       200\n",
      "weighted avg       0.84      0.83      0.83       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[84 13]\n",
      " [20 83]]\n",
      "=======================================================\n",
      "accuracy score 0.835\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(lgc, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0],  \n",
    "    'max_iter': [50, 100, 200] }  \n",
    "\n",
    "grid_search = GridSearchCV(lgc, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582b01d",
   "metadata": {},
   "source": [
    "## Passive Aggressive CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e13c815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        97\n",
      "           1       0.84      0.81      0.82       103\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.82      0.82       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [20 83]]\n",
      "=======================================================\n",
      "accuracy score 0.82\n"
     ]
    }
   ],
   "source": [
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(count_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(count_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1220345",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ff04fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.78125 0.76875 0.775   0.725   0.8375 ]\n",
      "Mean Accuracy: 0.7775000000000001\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 50}\n",
      "Best Accuracy Score: 0.78125\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        97\n",
      "           1       0.83      0.81      0.82       103\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.82      0.81       200\n",
      "weighted avg       0.82      0.81      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[80 17]\n",
      " [20 83]]\n",
      "=======================================================\n",
      "accuracy score 0.815\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0],  \n",
    "    'max_iter': [50, 100, 200]   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ae0d2",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "230ffae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79        97\n",
      "           1       0.82      0.73      0.77       103\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.78      0.78       200\n",
      "weighted avg       0.78      0.78      0.78       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [28 75]]\n",
      "=======================================================\n",
      "accuracy score 0.78\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(count_train, y_train)\n",
    "# make predictions on the test data\n",
    "y_pred = RFC.predict(count_test)\n",
    "# calculate metric evaluation and confusion matrix\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a969",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f24682b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.7625  0.6625  0.73125 0.79375 0.79375]\n",
      "Mean Accuracy: 0.74875\n",
      "Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10}\n",
      "Best Accuracy Score: 0.7575000000000001\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74        97\n",
      "           1       0.75      0.76      0.75       103\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.74      0.74      0.74       200\n",
      "weighted avg       0.74      0.74      0.74       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[71 26]\n",
      " [25 78]]\n",
      "=======================================================\n",
      "accuracy score 0.745\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(RFC, count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],     # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]        # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RFC, param_grid, cv=5, scoring='accuracy')\n",
    "random_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_RFC = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "predictions= best_RFC.predict(count_test)\n",
    "\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, predictions))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5324c5",
   "metadata": {},
   "source": [
    "## Xgboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2474546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        97\n",
      "           1       0.79      0.69      0.74       103\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.75      0.75      0.74       200\n",
      "weighted avg       0.75      0.74      0.74       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[78 19]\n",
      " [32 71]]\n",
      "=======================================================\n",
      "accuracy score 0.745\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(count_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb.predict(count_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e0a2",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "306ba18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.775   0.6375  0.74375 0.75    0.73125]\n",
      "Mean Accuracy: 0.7275\n",
      "Best Parameters: {'subsample': 0.7, 'min_child_weight': 6, 'max_depth': 10, 'gamma': 5, 'eta': 0.1}\n",
      "Best Accuracy Score: 0.6637500000000001\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64        97\n",
      "           1       0.66      0.67      0.66       103\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[61 36]\n",
      " [34 69]]\n",
      "=======================================================\n",
      "accuracy score 0.65\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb,count_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "params={'eta':[0.004,0.006,0.009,0.01,0.03,0.05,0.07,0.09,0.1,0.3],\n",
    " 'gamma':[5,10,15,20,25,30,40,50,60,70,80,90,100],\n",
    " 'max_depth':[int(x) for x in np.linspace(5,30,num=6)],\n",
    " 'min_child_weight':[3,4,5,6,7],\n",
    " 'subsample':[0.6,0.7,0.8]}\n",
    "\n",
    "    \n",
    "random_search = RandomizedSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
    "random_search.fit(count_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "y_pred_tuned = best_clf.predict(count_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913d1d4",
   "metadata": {},
   "source": [
    "# Word2Vec (Neural Networks Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2bdc635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9071098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14675052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "306fdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec(sent):\n",
    "    vector_size = wv.vector_size\n",
    "    wv_res = np.zeros(vector_size)\n",
    "    # print(wv_res)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in wv:\n",
    "            ctr += 1\n",
    "            wv_res += wv[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e22fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_review'] = df['Review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b43ade14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>tokenized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, loved, this, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, is, not, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture wa just nasty</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, tasty, and, the, texture, wa, just, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu wa great and so were...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, selection, on, the, menu, wa, great, and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked  \\\n",
       "0                               wow loved this place      1   \n",
       "1                                  crust is not good      0   \n",
       "2            not tasty and the texture wa just nasty      0   \n",
       "3  stopped by during the late may bank holiday of...      1   \n",
       "4  the selection on the menu wa great and so were...      1   \n",
       "\n",
       "                                    tokenized_review  \n",
       "0                          [wow, loved, this, place]  \n",
       "1                             [crust, is, not, good]  \n",
       "2   [not, tasty, and, the, texture, wa, just, nasty]  \n",
       "3  [stopped, by, during, the, late, may, bank, ho...  \n",
       "4  [the, selection, on, the, menu, wa, great, and...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c4c53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vector_rep']=df['tokenized_review'].apply(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7035db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>vector_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, loved, this, place]</td>\n",
       "      <td>[0.01357421875, 0.053125, 0.04287109375, 0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, is, not, good]</td>\n",
       "      <td>[-0.047711181640625, -0.0200927734375, 0.06809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture wa just nasty</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, tasty, and, the, texture, wa, just, nasty]</td>\n",
       "      <td>[0.04456329345703125, 0.06295394897460938, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
       "      <td>[-0.004427083333333333, 0.041651280721028645, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu wa great and so were...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, selection, on, the, menu, wa, great, and...</td>\n",
       "      <td>[-0.0016733805338541667, 0.09360758463541667, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked  \\\n",
       "0                               wow loved this place      1   \n",
       "1                                  crust is not good      0   \n",
       "2            not tasty and the texture wa just nasty      0   \n",
       "3  stopped by during the late may bank holiday of...      1   \n",
       "4  the selection on the menu wa great and so were...      1   \n",
       "\n",
       "                                    tokenized_review  \\\n",
       "0                          [wow, loved, this, place]   \n",
       "1                             [crust, is, not, good]   \n",
       "2   [not, tasty, and, the, texture, wa, just, nasty]   \n",
       "3  [stopped, by, during, the, late, may, bank, ho...   \n",
       "4  [the, selection, on, the, menu, wa, great, and...   \n",
       "\n",
       "                                          vector_rep  \n",
       "0  [0.01357421875, 0.053125, 0.04287109375, 0.058...  \n",
       "1  [-0.047711181640625, -0.0200927734375, 0.06809...  \n",
       "2  [0.04456329345703125, 0.06295394897460938, 0.0...  \n",
       "3  [-0.004427083333333333, 0.041651280721028645, ...  \n",
       "4  [-0.0016733805338541667, 0.09360758463541667, ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc24d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['vector_rep'].to_list()\n",
    "y=df['Liked'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "284cb4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01357422,  0.053125  ,  0.04287109,  0.05895081, -0.05151367,\n",
       "       -0.03081055,  0.07423096, -0.10703125,  0.02270508,  0.11113281,\n",
       "        0.01678467, -0.11672363,  0.00616455, -0.04345703,  0.03083496,\n",
       "        0.07419434,  0.05307617,  0.03364258,  0.03462524, -0.04174805,\n",
       "       -0.00231934,  0.07910156,  0.0854248 , -0.06704102,  0.03372803,\n",
       "       -0.01333618,  0.02128906,  0.0129715 ,  0.04265747, -0.05043945,\n",
       "       -0.09606934,  0.11972656, -0.01859131,  0.04973068,  0.05576477,\n",
       "       -0.04080963,  0.04460449, -0.00690918,  0.02219849,  0.15546875,\n",
       "        0.07652893, -0.11584473,  0.14025879,  0.03193359,  0.07636719,\n",
       "       -0.01558838,  0.02275391, -0.00559082, -0.01722412,  0.04335937,\n",
       "       -0.04697266,  0.08422852,  0.0107605 ,  0.00449219, -0.02585449,\n",
       "       -0.00258789,  0.00255127, -0.01152344,  0.0878418 , -0.0862793 ,\n",
       "       -0.0621582 ,  0.01035156, -0.01832275, -0.10610352,  0.00478516,\n",
       "       -0.04284668, -0.11657715,  0.02838135, -0.05606689,  0.13991699,\n",
       "        0.05848389, -0.01894531,  0.06816406,  0.04221802, -0.09343262,\n",
       "       -0.04746094, -0.01459961, -0.04375   ,  0.08360596,  0.13867188,\n",
       "       -0.01196289, -0.06494141,  0.02744141, -0.06220703, -0.14658203,\n",
       "       -0.0642334 , -0.0954834 ,  0.11940918, -0.02233887,  0.015625  ,\n",
       "        0.03334961,  0.04824219, -0.06826172, -0.13898926, -0.05432129,\n",
       "       -0.11191406, -0.01220703,  0.05151367, -0.03388672, -0.0847168 ,\n",
       "       -0.0859375 ,  0.05214844,  0.01643066, -0.00517578, -0.06484375,\n",
       "        0.01518555, -0.00219727, -0.07602539,  0.00283203, -0.12587891,\n",
       "       -0.04375   ,  0.11225586,  0.03586426,  0.04233398,  0.22205811,\n",
       "       -0.05915527,  0.00512695, -0.05227051,  0.0454834 , -0.02924805,\n",
       "       -0.06442871, -0.00986328,  0.0128418 ,  0.04052734,  0.04208984,\n",
       "       -0.05114746, -0.02133789, -0.03681641, -0.0434082 ,  0.05240173,\n",
       "       -0.12451172, -0.06289063, -0.04804688,  0.02655029,  0.05443573,\n",
       "       -0.01604004,  0.03460693,  0.00865784,  0.02788086,  0.06599121,\n",
       "        0.07285156, -0.0392334 ,  0.00927734, -0.06098633, -0.02734375,\n",
       "        0.10727539, -0.04516602, -0.02502441, -0.06523437, -0.05463867,\n",
       "        0.07138672,  0.0953125 , -0.01459961,  0.13171387, -0.13979492,\n",
       "       -0.02126465, -0.01191406,  0.00385742, -0.09898071, -0.05673828,\n",
       "       -0.05377197,  0.05166016, -0.04150391,  0.10981445,  0.02373047,\n",
       "       -0.05859375,  0.06904297, -0.05751953, -0.03339844,  0.05554199,\n",
       "       -0.09580078, -0.05222168, -0.02927246, -0.05380859, -0.04353027,\n",
       "        0.04971924,  0.07546692, -0.04190674,  0.02312012, -0.00349121,\n",
       "       -0.03652344, -0.01437988,  0.07099609, -0.00463867, -0.03846741,\n",
       "       -0.11689453, -0.05454102,  0.01154785,  0.04602051, -0.00854492,\n",
       "       -0.02055359,  0.06279297,  0.06100464, -0.03181763, -0.03382568,\n",
       "        0.05065918,  0.05546875,  0.03271484, -0.06296997, -0.14316406,\n",
       "       -0.03578491,  0.06933594, -0.08300781, -0.02119141, -0.00974121,\n",
       "        0.00228271, -0.03654785,  0.00314941,  0.00996094,  0.04501953,\n",
       "        0.04599609,  0.10136719, -0.05288086, -0.04201229, -0.14160156,\n",
       "       -0.02878418,  0.12246094,  0.01894531, -0.04228516, -0.08479004,\n",
       "       -0.03242188,  0.08869629, -0.01124268,  0.008255  ,  0.01889648,\n",
       "       -0.05205078,  0.00175781, -0.04032288, -0.06357422,  0.00932617,\n",
       "        0.02216797, -0.0581543 ,  0.01497803,  0.01699219,  0.14370117,\n",
       "       -0.027771  , -0.03071594, -0.02055664,  0.11411133,  0.03105469,\n",
       "       -0.00946045, -0.0324707 , -0.01670837, -0.03867798, -0.09272461,\n",
       "        0.05272827,  0.02788086, -0.04348145, -0.02133789, -0.14787598,\n",
       "       -0.09938965,  0.11410522,  0.0993042 ,  0.04287109,  0.04359131,\n",
       "       -0.04587097, -0.03564453,  0.00044556, -0.13701172, -0.14702148,\n",
       "       -0.02275391, -0.06611328,  0.02026367,  0.02255859,  0.03127441,\n",
       "        0.05419922,  0.03845215,  0.00422363, -0.03154297, -0.03130646,\n",
       "        0.02519531,  0.12421875,  0.09289551,  0.08530273,  0.08647461,\n",
       "       -0.07268372, -0.09421387, -0.06777344, -0.05415039, -0.01416016,\n",
       "        0.08413086, -0.02373047, -0.06166992,  0.0762207 ,  0.02646484,\n",
       "       -0.02004395, -0.09208984, -0.06621094, -0.02648926, -0.0050293 ,\n",
       "       -0.05458984,  0.02000122, -0.1418335 , -0.00371094, -0.10593262,\n",
       "       -0.07407227, -0.00494385, -0.05335083,  0.03540039, -0.06333008])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d531556e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f13345",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc16784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84        97\n",
      "           1       0.90      0.77      0.83       103\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.84      0.84      0.83       200\n",
      "weighted avg       0.84      0.83      0.83       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[88  9]\n",
      " [24 79]]\n",
      "=======================================================\n",
      "accuracy score 0.835\n"
     ]
    }
   ],
   "source": [
    "lgc = LogisticRegression()\n",
    "lgc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lgc.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17546a",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "480f1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.825   0.79375 0.8125  0.79375 0.8625 ]\n",
      "Mean Accuracy: 0.8174999999999999\n",
      "Best Parameters: {'C': 2.0, 'max_iter': 50}\n",
      "Best Accuracy Score: 0.8275\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        97\n",
      "           1       0.90      0.79      0.84       103\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.85      0.84       200\n",
      "weighted avg       0.85      0.84      0.84       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[88  9]\n",
      " [22 81]]\n",
      "=======================================================\n",
      "accuracy score 0.845\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(lgc, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0], \n",
    "    'max_iter': [50, 100, 200]  }\n",
    "\n",
    "grid_search = GridSearchCV(lgc, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(X_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396d12d",
   "metadata": {},
   "source": [
    "## Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01f060ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83        97\n",
      "           1       0.88      0.76      0.81       103\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.82      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[86 11]\n",
      " [25 78]]\n",
      "=======================================================\n",
      "accuracy score 0.82\n"
     ]
    }
   ],
   "source": [
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46156704",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a359fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.85625 0.79375 0.8375  0.7875  0.83125]\n",
      "Mean Accuracy: 0.82125\n",
      "Best Parameters: {'C': 0.5, 'max_iter': 200}\n",
      "Best Accuracy Score: 0.82875\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80        97\n",
      "           1       0.88      0.67      0.76       103\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.80      0.79      0.78       200\n",
      "weighted avg       0.81      0.79      0.78       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[88  9]\n",
      " [34 69]]\n",
      "=======================================================\n",
      "accuracy score 0.785\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0],  \n",
    "    'max_iter': [50, 100, 200]   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "prediction = best_clf.predict(X_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, prediction)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, prediction))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206b732",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39dac0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        97\n",
      "           1       0.83      0.78      0.80       103\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.80       200\n",
      "weighted avg       0.81      0.81      0.80       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [23 80]]\n",
      "=======================================================\n",
      "accuracy score 0.805\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train, y_train)\n",
    "# make predictions on the test data\n",
    "y_pred = RFC.predict(X_test)\n",
    "# calculate metric evaluation and confusion matrix\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0ca7d",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74a21ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.775   0.74375 0.75625 0.75625 0.8625 ]\n",
      "Mean Accuracy: 0.7787499999999999\n",
      "Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "Best Accuracy Score: 0.79625\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.79        97\n",
      "           1       0.83      0.75      0.79       103\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [26 77]]\n",
      "=======================================================\n",
      "accuracy score 0.79\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(RFC, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],     # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]        # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RFC, param_grid, cv=5, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_RFC = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "predictions= best_RFC.predict(X_test)\n",
    "\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, predictions))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e0eba",
   "metadata": {},
   "source": [
    "# Xgboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1425653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79        97\n",
      "           1       0.83      0.74      0.78       103\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.78       200\n",
      "weighted avg       0.79      0.79      0.78       200\n",
      "\n",
      "=======================================================\n",
      "Confusion Matrix:\n",
      "\n",
      " [[81 16]\n",
      " [27 76]]\n",
      "=======================================================\n",
      "accuracy score 0.785\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print the result\n",
    "\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "print(\"=\"*55)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b306906",
   "metadata": {},
   "source": [
    "## Cross Validation And Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce427022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.84375 0.7625  0.775   0.71875 0.84375]\n",
      "Mean Accuracy: 0.7887500000000001\n",
      "Best Parameters: {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 30, 'gamma': 10, 'eta': 0.05}\n",
      "Best Accuracy Score: 0.7862500000000001\n",
      "Tuned Model Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        97\n",
      "           1       0.85      0.74      0.79       103\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.81      0.80      0.80       200\n",
      "weighted avg       0.81      0.80      0.80       200\n",
      "\n",
      "=======================================================\n",
      "Tuned Model Confusion Matrix:\n",
      "\n",
      " [[84 13]\n",
      " [27 76]]\n",
      "=======================================================\n",
      "accuracy score 0.8\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb,X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "params={'eta':[0.004,0.006,0.009,0.01,0.03,0.05,0.07,0.09,0.1,0.3],\n",
    " 'gamma':[5,10,15,20,25,30,40,50,60,70,80,90,100],\n",
    " 'max_depth':[int(x) for x in np.linspace(5,30,num=6)],\n",
    " 'min_child_weight':[3,4,5,6,7],\n",
    " 'subsample':[0.6,0.7,0.8]}\n",
    "\n",
    "    \n",
    "random_search = RandomizedSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best classifier with tuned hyperparameters\n",
    "best_clf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "y_pred_tuned = best_clf.predict(X_test)\n",
    "# Calculate metric evaluations and confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "\n",
    "print(\"Tuned Model Classification Report:\\n\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"=\"*55)\n",
    "print(\"Tuned Model Confusion Matrix:\\n\\n\", cm_tuned)\n",
    "print(\"=\"*55)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70013e3d",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aac818",
   "metadata": {},
   "source": [
    "### Among the vectorization techniques word2vec has resulted in better accuracy than rest other techniques.\n",
    "### The best accuracy is achieved through Word2Vec using Logistic Regression\n",
    "### The best accuracy score is 0.845"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2f9bc",
   "metadata": {},
   "source": [
    "# Reason for Word2Vec Better Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87997af",
   "metadata": {},
   "source": [
    "### Word2Vec has better Semantic Understanding than Tfidf and Bag of Words\n",
    "\n",
    "### Also Word2Vec is a neural network based model and Neural networks, especially deep learning models, have proven to be highly effective in handling the complexity and non-linearity inherent in language data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af97caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
